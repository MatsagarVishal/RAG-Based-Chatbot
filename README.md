# ğŸ§  RAG-Based Chatbot for Any Website URL

A  headless Retrieval-Augmented Generation (RAG) backend** that crawls any website, builds a per-site knowledge base, and answers user questions using semantic search + LLMs.

This project is designed to be:
- âœ… Multi-user
- âœ… Deployable
- âœ… Frontend-agnostic (React, Streamlit, mobile, etc.)
- âœ… Scalable & modular

---

## ğŸš€ Features

- ğŸŒ Crawl any public website (up to configurable depth)
- ğŸ§¹ Clean & preprocess HTML content
- âœ‚ï¸ Chunk text intelligently
- ğŸ§  Generate embeddings using Sentence Transformers
- ğŸ“¦ Store vectors using FAISS (per-website isolation)
- ğŸ” Retrieve relevant context via semantic search
- ğŸ¤– Generate answers using **Groq LLMs**
- ğŸ§© Headless REST APIs (FastAPI)

---

## ğŸ—ï¸ High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend   â”‚  (React / Streamlit / Any Client)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ HTTPS (JSON)
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     FastAPI Backend      â”‚
â”‚  (Stateless, Headless)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â”‚
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚  Crawl Service   â”‚
 â”‚  (Website â†’ KB)  â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ Knowledge Base (KB)  â”‚
 â”‚  - Clean text        â”‚
 â”‚  - Chunking          â”‚
 â”‚  - Embeddings        â”‚
 â”‚  - FAISS Index       â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚   RAG Chat Service   â”‚
 â”‚  - Semantic Search  â”‚
 â”‚  - Prompt Builder   â”‚
 â”‚  - Groq LLM         â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§© Detailed Component Architecture

```
rag-backend/
â”‚
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ main.py              # FastAPI app entry
â”‚   â””â”€â”€ routes/
â”‚       â”œâ”€â”€ crawl.py         # /api/crawl
â”‚       â””â”€â”€ chat.py          # /api/chat
â”‚
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ crawl_service.py     # Crawl + KB workflow
â”‚   â””â”€â”€ chat_service.py      # RAG query workflow
â”‚
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ crawler/
â”‚   â”‚   â”œâ”€â”€ crawler.py       # Website crawling logic
â”‚   â”‚   â””â”€â”€ utils.py
â”‚   â”‚
â”‚   â”œâ”€â”€ kb/
â”‚   â”‚   â”œâ”€â”€ build_kb.py      # Chunking + embedding
â”‚   â”‚   â””â”€â”€ vector_store.py  # FAISS save/load
â”‚   â”‚
â”‚   â””â”€â”€ rag/
â”‚       â””â”€â”€ qa_chain.py      # Retrieval + LLM logic
â”‚
â”œâ”€â”€ schemas/
â”‚   â”œâ”€â”€ crawl.py             # Request/response models
â”‚   â””â”€â”€ chat.py
â”‚
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ url_hash.py          # URL â†’ kb_id
â”‚
â”œâ”€â”€ storage/
â”‚   â””â”€â”€ data/
â”‚       â””â”€â”€ <kb_id>/         # One folder per website
â”‚           â”œâ”€â”€ raw_pages.json
â”‚           â”œâ”€â”€ faiss.index
â”‚           â””â”€â”€ metadata.pkl
â”‚
â”œâ”€â”€ .env                     # Environment variables
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ”„ End-to-End Data Flow

### 1ï¸âƒ£ Build Knowledge Base

```
Client â†’ POST /api/crawl
        â†“
Backend:
- Validate URL
- Generate kb_id
- Crawl website
- Clean & extract text
- Chunk content
- Generate embeddings
- Store FAISS index
```

### 2ï¸âƒ£ Ask a Question

```
Client â†’ POST /api/chat
        â†“
Backend:
- Load FAISS index by kb_id
- Embed user question
- Retrieve top-k chunks
- Build RAG prompt
- Query Groq LLM
- Return answer + sources
```

---

## ğŸŒ API Reference

### ğŸ”¹ Health Check
```
GET /health
```
Response:
```json
{ "status": "ok" }
```

---

### ğŸ”¹ Crawl Website
```
POST /api/crawl
```
Request:
```json
{
  "url": "https://example.com"
}
```
Response:
```json
{
  "kb_id": "example_com",
  "status": "completed",
  "pages_crawled": 1
}
```

---

### ğŸ”¹ Chat with Website
```
POST /api/chat
```
Request:
```json
{
  "kb_id": "example_com",
  "question": "What is this website about?"
}
```
Response:
```json
{
  "answer": "Example.com is used for illustrative purposes.",
  "sources": ["https://example.com"]
}
```

---

## ğŸ” Environment Variables

Create a `.env` file:

```env
GROQ_API_KEY=your_groq_api_key_here
```

---

## ğŸ§  Design Decisions & Rationale

- **Stateless backend** â†’ scalable & cloud-friendly
- **Per-website vector stores** â†’ multi-user safe
- **FAISS** â†’ fast local vector search
- **Sentence Transformers** â†’ high-quality embeddings
- **Groq LLMs** â†’ fast inference & free tier
- **FastAPI** â†’ async, high performance, OpenAPI support

---

## ğŸš€ Deployment

This backend supports multiple deployment options:

### ğŸ  Local Development

```bash
# Install dependencies
pip install -r requirements.txt

# Install Playwright browsers
playwright install chromium

# Create .env file
cp .env.example .env
# Edit .env and add your GROQ_API_KEY

# Run locally
uvicorn api.main:app --reload
```

### ğŸ³ Docker (Local)

```bash
# Create .env file
cp .env.example .env
# Edit .env with your configuration

# Build and run
docker-compose up --build -d

# View logs
docker-compose logs -f

# Access API
curl http://localhost:8000/health
```

### â˜ï¸ AWS EC2 Deployment (Recommended)

**Quick Start:**

1. **Create S3 Bucket** (for persistent storage):
   ```bash
   aws s3 mb s3://rag-chatbot-storage-<your-unique-id>
   ```

2. **Launch EC2 Instance** (t3.medium or larger recommended)

3. **SSH into EC2 and run setup script**:
   ```bash
   curl -O https://raw.githubusercontent.com/your-repo/rag-chatbot/main/ec2-setup.sh
   chmod +x ec2-setup.sh
   ./ec2-setup.sh
   ```

4. **Configure environment** (`.env`):
   ```env
   GROQ_API_KEY=your_key_here
   STORAGE_BACKEND=s3
   S3_BUCKET_NAME=rag-chatbot-storage-<your-unique-id>
   AWS_REGION=us-east-1
   ```

5. **Access your API**:
   ```
   http://<EC2_PUBLIC_IP>:8000
   ```

ğŸ“š **[Complete EC2 Deployment Guide](./docs/ec2-deployment.md)** - Detailed step-by-step instructions

### ğŸŒ Other Cloud Platforms

- **AWS App Runner**: Fully managed, auto-scaling (~$26-50/month)
- **AWS ECS Fargate**: Production-grade containers (~$80-120/month)
- **Render**: Easy deployment with free tier
- **Railway**: Simple deployment with automatic HTTPS

---

## âš™ï¸ Configuration

### Environment Variables

Create a `.env` file (use `.env.example` as template):

```env
# Required
GROQ_API_KEY=your_groq_api_key_here

# Storage Backend ('local' or 's3')
STORAGE_BACKEND=local

# Local Storage (only if STORAGE_BACKEND=local)
STORAGE_ROOT=storage/data

# AWS S3 Storage (only if STORAGE_BACKEND=s3)
S3_BUCKET_NAME=rag-chatbot-storage
AWS_REGION=us-east-1

# Optional
PORT=8000
LOG_LEVEL=INFO
```

### Storage Backends

**Local Storage** (Development):
- Data stored in `storage/data/` directory
- Fast, no external dependencies
- Data lost if container is removed

**S3 Storage** (Production):
- Data persisted in AWS S3
- Survives container restarts
- Enables horizontal scaling
- Automatic backups with versioning

---

## ğŸ† What This Project Demonstrates

- Real-world RAG architecture
- Backend system design
- API-first development
- LLM integration
- Vector databases (FAISS)
- Cloud-native deployment (AWS S3 integration)
- Docker containerization
- Clean, modular codebase

---

## ğŸ“Œ Future Enhancements

- Authentication & rate limiting
- Chat history & sessions
- Streaming responses
- Hybrid search (BM25 + vectors)
- UI dashboard (React)
- Migration to managed vector DB (Pinecone, Weaviate)

---

